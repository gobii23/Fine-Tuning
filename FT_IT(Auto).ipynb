{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBCcoHbC9xkA",
    "outputId": "913ba689-3410-4251-a631-c792a378e815"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.5.23)\n",
      "Requirement already satisfied: crewai in /usr/local/lib/python3.11/dist-packages (0.159.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.9)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.46.3)\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.12.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2024.8)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.116.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.25.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.57b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.4.4)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.2.1)\n",
      "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.10.0)\n",
      "Requirement already satisfied: json-repair==0.25.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.25.2)\n",
      "Requirement already satisfied: json5>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.12.1)\n",
      "Requirement already satisfied: jsonref>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.1.0)\n",
      "Requirement already satisfied: litellm==1.74.9 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.74.9)\n",
      "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.99.9)\n",
      "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.36.0)\n",
      "Requirement already satisfied: pdfplumber>=0.11.4 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.11.7)\n",
      "Requirement already satisfied: portalocker==2.7.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.7.0)\n",
      "Requirement already satisfied: pyjwt>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.10.1)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.1.1)\n",
      "Requirement already satisfied: pyvis>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.3.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai) (2024.11.6)\n",
      "Requirement already satisfied: tomli-w>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.2.1)\n",
      "Requirement already satisfied: uv>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.8.12)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (3.12.15)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (4.25.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (0.11.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: crewai-tools~=0.62.0 in /usr/local/lib/python3.11/dist-packages (from crewai[tools]) (0.62.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.74)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.10.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: docker>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools~=0.62.0->crewai[tools]) (7.1.0)\n",
      "Requirement already satisfied: embedchain>=0.1.114 in /usr/local/lib/python3.11/dist-packages (from crewai-tools~=0.62.0->crewai[tools]) (0.1.128)\n",
      "Requirement already satisfied: lancedb>=0.5.4 in /usr/local/lib/python3.11/dist-packages (from crewai-tools~=0.62.0->crewai[tools]) (0.24.3)\n",
      "Requirement already satisfied: pyright>=1.1.350 in /usr/local/lib/python3.11/dist-packages (from crewai-tools~=0.62.0->crewai[tools]) (1.1.403)\n",
      "Requirement already satisfied: pytube>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools~=0.62.0->crewai[tools]) (15.0.0)\n",
      "Requirement already satisfied: stagehand>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from crewai-tools~=0.62.0->crewai[tools]) (0.5.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.47.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (5.6.3)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.17.0)\n",
      "Requirement already satisfied: jiter<0.11,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.74.9->crewai) (3.0.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.3.45)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.3)\n",
      "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.9.1)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (20250506)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (3.4.3)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (43.0.3)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (1.20.1)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (1.16.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (4.13.4)\n",
      "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.1.44)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.3.27)\n",
      "Requirement already satisfied: langchain-cohere<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.3.5)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.3.27)\n",
      "Requirement already satisfied: langchain-openai<0.3.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.2.14)\n",
      "Requirement already satisfied: mem0ai<0.2.0,>=0.1.54 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.1.116)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (5.9.0)\n",
      "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.3.4)\n",
      "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.7.7)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (2.0.43)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.74.9->crewai) (3.23.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.19.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.51)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai) (0.27.0)\n",
      "Requirement already satisfied: deprecation in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai-tools~=0.62.0->crewai[tools]) (2.1.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: nodeenv>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyright>=1.1.350->crewai-tools~=0.62.0->crewai[tools]) (1.9.1)\n",
      "Requirement already satisfied: playwright>=1.42.1 in /usr/local/lib/python3.11/dist-packages (from stagehand>=0.4.1->crewai-tools~=0.62.0->crewai[tools]) (1.54.0)\n",
      "Requirement already satisfied: browserbase>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from stagehand>=0.4.1->crewai-tools~=0.62.0->crewai[tools]) (1.4.0)\n",
      "Requirement already satisfied: anthropic>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from stagehand>=0.4.1->crewai-tools~=0.62.0->crewai[tools]) (0.64.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (1.1.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (2.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (1.17.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.3.9)\n",
      "Requirement already satisfied: cohere<6.0,>=5.5.6 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (5.17.0)\n",
      "Requirement already satisfied: langchain-experimental<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.3.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.9.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.4.0)\n",
      "Requirement already satisfied: qdrant-client>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (1.15.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
      "Requirement already satisfied: pyee<14,>=13 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.42.1->stagehand>=0.4.1->crewai-tools~=0.62.0->crewai[tools]) (13.0.0)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.42.1->stagehand>=0.4.1->crewai-tools~=0.62.0->crewai[tools]) (3.2.4)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (2.22)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (1.12.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (2.32.4.20250809)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (0.9.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (4.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (1.1.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools~=0.62.0->crewai[tools]) (4.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb crewai crewai['tools'] datasets langchain-google-genai matplotlib pandas pydantic scikit-learn seaborn torch transformers trl tqdm unsloth\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from crewai.tools import BaseTool\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "class FTTool(BaseTool):\n",
    "    name: str = \"FTTool\"\n",
    "    description: str = (\n",
    "        \"Fine-tunes a HuggingFace model for a given task type. \"\n",
    "        \"Requires: model_name, dataset_name_or_path, task_type (causal_lm, sequence_classification, token_classification, etc.), \"\n",
    "        \"and optional training arguments.\"\n",
    "    )\n",
    "\n",
    "    def _run(\n",
    "        self, model_name: str, dataset_name_or_path: str, task_type: str, **kwargs\n",
    "    ) -> str:\n",
    "        try:\n",
    "            model_loader_map = {\n",
    "                \"causal_lm\": AutoModelForCausalLM,\n",
    "                \"sequence_classification\": AutoModelForSequenceClassification,\n",
    "                \"token_classification\": AutoModelForTokenClassification,\n",
    "            }\n",
    "            if task_type not in model_loader_map:\n",
    "                return json.dumps(\n",
    "                    {\n",
    "                        \"status\": \"error\",\n",
    "                        \"message\": f\"Unsupported task_type '{task_type}'. Supported: {list(model_loader_map.keys())}\",\n",
    "                    },\n",
    "                    indent=2,\n",
    "                )\n",
    "\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            if task_type == \"causal_lm\" and tokenizer.pad_token is None:\n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "            model = model_loader_map[task_type].from_pretrained(model_name)\n",
    "\n",
    "            # Load dataset\n",
    "            if os.path.exists(dataset_name_or_path):\n",
    "                dataset = load_dataset(\"json\", data_files=dataset_name_or_path)\n",
    "            else:\n",
    "                dataset = load_dataset(dataset_name_or_path)\n",
    "\n",
    "            # Ensure validation split exists\n",
    "            if \"validation\" not in dataset:\n",
    "                if \"test\" in dataset:\n",
    "                    dataset[\"validation\"] = dataset[\"test\"]\n",
    "                elif \"train\" in dataset:\n",
    "                    split_dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "                    dataset[\"train\"] = split_dataset[\"train\"]\n",
    "                    dataset[\"validation\"] = split_dataset[\"test\"]\n",
    "\n",
    "            def tokenize_function(examples):\n",
    "                max_len = kwargs.get(\n",
    "                    \"max_length\", 512 if task_type == \"causal_lm\" else 256\n",
    "                )\n",
    "                return tokenizer(\n",
    "                    examples[\"text\"],\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\",\n",
    "                    max_length=max_len,\n",
    "                )\n",
    "\n",
    "            tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "            # Adjust evaluation strategy\n",
    "            eval_strategy = kwargs.get(\n",
    "                \"evaluation_strategy\",\n",
    "                \"epoch\" if \"validation\" in tokenized_datasets else \"no\",\n",
    "            )\n",
    "\n",
    "            output_dir = \"./output/fine_tuning_results\"\n",
    "            train_args = TrainingArguments(\n",
    "                output_dir=output_dir,\n",
    "                eval_strategy=eval_strategy,\n",
    "                learning_rate=kwargs.get(\"learning_rate\", 5e-5),\n",
    "                per_device_train_batch_size=kwargs.get(\"train_batch_size\", 4),\n",
    "                per_device_eval_batch_size=kwargs.get(\"eval_batch_size\", 4),\n",
    "                num_train_epochs=kwargs.get(\"num_epochs\", 3),\n",
    "                weight_decay=kwargs.get(\"weight_decay\", 0.01),\n",
    "                logging_dir=os.path.join(output_dir, \"logs\"),\n",
    "                logging_steps=kwargs.get(\"logging_steps\", 50),\n",
    "                save_strategy=\"epoch\",\n",
    "                report_to=kwargs.get(\"report_to\", \"none\"),\n",
    "                push_to_hub=False,\n",
    "            )\n",
    "\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=train_args,\n",
    "                train_dataset=tokenized_datasets[\"train\"],\n",
    "                eval_dataset=tokenized_datasets.get(\"validation\"),\n",
    "                tokenizer=tokenizer,\n",
    "            )\n",
    "\n",
    "            trainer.train()\n",
    "\n",
    "            model.save_pretrained(output_dir)\n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "            return json.dumps(\n",
    "                {\n",
    "                    \"status\": \"success\",\n",
    "                    \"output_dir\": output_dir,\n",
    "                    \"message\": f\"Fine-tuned {model_name} for {task_type} saved at {output_dir}\",\n",
    "                },\n",
    "                indent=2,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"status\": \"error\", \"message\": str(e)}, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"dummy\"\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"GEMINI_API_KEY\"\n",
    "\n",
    "# LLM\n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-2.5-flash\"\n",
    ")\n",
    "\n",
    "\n",
    "# TOOLS\n",
    "ft_tool = FTTool()\n",
    "\n",
    "\n",
    "# INPUT\n",
    "ft_model_name = input(\"Enter the name of the model: \")\n",
    "ft_task_type = input(\"Enter task type (causal_lm, sequence_classification, token_classification): \")\n",
    "ft_dataset = input(\"Enter dataset name or path: \")\n",
    "\n",
    "\n",
    "ft_agent = Agent(\n",
    "    role=\"HuggingFace Fine-Tuning Expert\",\n",
    "    goal=(\n",
    "        \"\"\"Act as a top-tier HuggingFace trainer capable of orchestrating the entire fine-tuning pipeline.\n",
    "        Guide the user to select a valid HuggingFace task type ('causal_lm', 'sequence_classification', or 'token_classification'),\n",
    "        validate all provided inputs including model_name, dataset_name_or_path, and training arguments,\n",
    "        auto-correct obvious parameter mistakes, dynamically load the correct transformer model class,\n",
    "        prepare datasets with optimal tokenization strategies for the task type,\n",
    "        configure sensible but high-performing defaults for TrainingArguments while honoring user overrides,\n",
    "        and execute fine-tuning exclusively using the FTTool.\n",
    "        Return only the exact JSON object provided by FTTool — no extra commentary, formatting, or explanation.\"\"\"\n",
    "    ),\n",
    "    backstory=(\n",
    "        \"\"\"You are an elite machine learning architect with deep expertise in HuggingFace Transformers,\n",
    "        specializing in maximizing training efficiency and model performance.\n",
    "        Over the years, you’ve orchestrated countless fine-tuning runs across NLP tasks,\n",
    "        balancing precision engineering with rapid prototyping.\n",
    "        You are obsessive about parameter validation, preventing wasted GPU cycles,\n",
    "        and ensuring reproducibility. Your workflow is surgical:\n",
    "        prompt, validate, adapt, execute, and deliver — with zero noise in the output.\"\"\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "\n",
    "ft_task_transformer = Task(\n",
    "    description=f\"\"\"\n",
    "        Prompt the user to choose the HuggingFace task type they want to perform (options: \"causal_lm\", \"sequence_classification\", or \"token_classification\").\n",
    "        Once the task type is selected, automatically collect and validate all required parameters:\n",
    "        a. model_name (string, valid HuggingFace model ID or local path)\n",
    "        b. dataset_name_or_path (string, valid HuggingFace dataset name or local file path)\n",
    "        c. task_type (string, must be one of the supported task types)\n",
    "        d. optional training arguments (learning_rate, num_epochs, train_batch_size, eval_batch_size, max_length, evaluation_strategy, weight_decay, logging_steps).\n",
    "\n",
    "        Fine-tune the HuggingFace model {ft_model_name} for the task {ft_task_type} using the dataset {ft_dataset}.\n",
    "        Use the FineTuneTool to configure and run training. Pass model_name='{ft_model_name}, dataset_name_or_path={ft_dataset}, task_type={ft_task_type}, and any additional training arguments.\n",
    "\n",
    "        After collecting and validating inputs:\n",
    "        1. Dynamically load the correct model class based on task_type:\n",
    "            a. causal_lm -> AutoModelForCausalLM\n",
    "            b. sequence_classification -> AutoModelForSequenceClassification\n",
    "            c. token_classification -> AutoModelForTokenClassification\n",
    "        2. Load and tokenize the dataset according to task_type, applying appropriate truncation, padding, and max_length rules.\n",
    "        3. Automatically configure TrainingArguments with sensible defaults, allowing overrides from user-supplied training arguments.\n",
    "        4. Run fine-tuning using the FTTool, passing model_name, dataset_name_or_path, task_type, and all additional arguments to `_run()`.\n",
    "        5. On completion, return **only** the JSON string returned by FTTool containing:\n",
    "            a. \"status\" (success or error)\n",
    "            b. \"output_dir\" (model save path)\n",
    "            c. \"message\" (summary of fine-tuning)\n",
    "        Do not include any additional text, explanations, or formatting outside the returned JSON.\"\"\",\n",
    "    expected_output=\"\"\"A single JSON object returned by the FineTuneTool containing exactly these keys:\n",
    "        model_save_path(string) – the path where the fine-tuned model is stored, training_details(object) – metrics and configuration used during training,and status (string) – the final training status (e.g., 'success', 'failed').\n",
    "        No extra text, explanations, or formatting outside of the JSON object.\"\"\",\n",
    "    tools=[ft_tool],\n",
    "    agent=ft_agent,\n",
    ")\n",
    "\n",
    "\n",
    "# CREW\n",
    "crew = Crew(\n",
    "    agents=[ft_agent],\n",
    "    tasks=[ft_task_transformer],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "# KICKOFF\n",
    "result = crew.kickoff()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "dc931a9942274ad89c98850013a8ee54",
      "c9dad5de581945c49870c6c34780e5af",
      "8c9da58ef6624dafb4aaa2fbcff513c6",
      "d4d1d21bc415487792af92669284d1f2",
      "6ce6a1f19efd4510a879bfd04291918b",
      "be518fbf12254f13b9dd0159fe0080b7",
      "3c915cbe18a74319ae26b7d64574dbc1",
      "9cc3ca31b85842d9979268e364609787",
      "f2e46d8cce6d4532a731704b31d371ac",
      "4f2f736841a74eee9f794041037fbff9",
      "e510cae7f56a439e83097ecfd382c60c",
      "771a03e2dc1641b7b21c65f240507a80",
      "86f32754b8a74ea585eca1322b83e5e8",
      "7e69ed6351874b7ebf1f87a8e2ef4d84",
      "0e2326a6b8e84b6a977d67602e6b423f",
      "417377e758da4769b375dae07ea40775",
      "afaf489f52ff4f3bb6ebe86342bce741",
      "8c6b400ca1be463ea73a06fc52cda8cc",
      "613d8d09b0cf4cedab7d79500a835258",
      "16dbc0cc174e472abe8c17c927e2a949",
      "86e90e365b48435f8d7668ffcae937e4",
      "3dd6da0778c54d37b2ba2a650ef80b9a",
      "19952dc481d544d0a47cd493c4ffecd9",
      "bf3e925f90d54535a2945c129406d338",
      "023ccf4ef88945e4bc5dbde33311af0f",
      "562d5ed8ca45429e97eac3ed7b964067",
      "932005c99ec74abd8c0d4b4bccbb6123",
      "307650f10a90490f8e24be363eeb8012",
      "c8fc46bab3084d6fafddac5c7ef37ddc",
      "4149b3c38f744ec49bbf82089e4b1f69",
      "c8e443ea43f44d44a7a8d7affb118987",
      "aa69980e9b29492bb774fe12329f0e30",
      "7bb1d5f47f124e95bb67409b9a8ac9fd",
      "8dc032509d7a45719e96d9731929be6b",
      "44ce2ee470344ea58a69a9fbc51fa317",
      "c3a7bf5ddc7e471ca4f1930bb4b8bf9e",
      "f33b1c84d80841538662b86e123e2a7f",
      "cf102cee5a324f0786a0231c494811da",
      "461967468ba642ce9b3a6cea1ddc906c",
      "2c99f01993b1438dbfb9824b6b4dbada",
      "a584ccc5d3d54a06a26fc60acd631c84",
      "b917875b4e9c4bdda42a9114c4d01611",
      "57f2131721504af4bd588ae416b3cbe3",
      "e264aa2d40d2480aa7dad62ed9714e96",
      "0c52307720f347e0a0d30f463793ee8f",
      "12868795eb9e436e90fa7273272b6967",
      "6fa01ec95da943a1a5aa6e95636c44c0",
      "2f2f06d99e324ce4a144a69b43fb9bcb",
      "236c7b6f2c88460cb07657eb90ff30da",
      "ced20548e8cc41b89560351dfe62c391",
      "67766c956c924e4eb417233ee4af3d57",
      "f43debcc3f064ce0a0be57656ee310c4",
      "fe38187cd20946b3acd25e1f28d04ac9",
      "67b0ad1e76cd47f38ea17edc3d4117a7",
      "499f5b49645342e49518e2a73c7a9d9d",
      "9e8bf775ed0a4b8783c2266348b24532",
      "d20fc04c036e4eac9cd5bee8b72d4820",
      "1a650c82e9ed4aee991adcd3d69f67e6",
      "cff75d571aa747aeadf076cb2a7e863a",
      "2eb6851a0dcd49baabadf352d0950261",
      "7617691f3f764e3da6630e030d63c0f8",
      "bcd41bef927a40b49a123c4c7e8753eb",
      "e78586ae68ba43e390380c802995d2a9",
      "8cda3cd58bf743ef844803607c964c68",
      "3226ffc3ce5e43a39ce3ab3cfcca8ac2",
      "61ab382af2664ab1a7847a96a8dbf76c",
      "3f8dc340cf16435797ed1529585c328a",
      "5d7f58415114432ba102602b55a19ea6",
      "b920a972007346bebf7b46926e09c9ac",
      "3ea22ed53a1c40e1ac1637edf3ab47de",
      "04c7cf6b84014c089cec073f626a3a1e",
      "3fa1ef0d52504a5fb60eec1cd9958c41",
      "69038e21734e4d88944520a6df0671f6",
      "bf517a9e072949b3b2706954170fd671",
      "1052e9de7dc8478bb01261fff20f960f",
      "b7dedc6686724d338e886afaa313e5fd",
      "6a1882ec9267474fb259aa1ee30e900a",
      "7b00f2af2690480a972b5b021a1f943d",
      "cbeed927d5ab4d8097fce1f5438bfc2d",
      "70663b54c893426bacb56a658a8d1380",
      "86b4ad290e784d669735e20d8607aa3e",
      "c4d3ac131d5f423ba809d1acdfe511a8",
      "60ee8802e4b644eca771cd23ad533865",
      "a7a91a3226704d948189fa9963f0eab0",
      "efe56a7e1d774274842424e5ae52aa1c",
      "c8c8437c213341f99241c53ba6bb9ee8",
      "907abd06319b400da71a6e52db57cf0e",
      "948870cda92d4b6a9874cba7b2269f33",
      "d0f5d6dac009497a83ad6dc3c2e87d8e",
      "05b03744073d4cb682ecf8eba892e0a9",
      "3adf93757a0d46b0b9a496044f34a0ad",
      "0d20b96e92324a468d37e29d620c4ddd",
      "1e6ab84cb000492281c2e6190e319fbc",
      "5bd8d0bbe9564ad289cfcd9d34f85639",
      "5adc4f7146b8455b886f7b0f995ced12",
      "28db3fbf6aeb4ad6a3d02aacaaf86b42",
      "a2e2e79d4bba49d59a67470db9605191",
      "3e93357d857f49c6b601d4d1a2cb200d",
      "21945f914b0f40caa6d27072970fe671",
      "5e7b52bfe4e447a1a4ec33c7e70bc8de",
      "9139f2dd771544aabe386c5c1223ca9f",
      "eb481acaf2234c9287eb42f293e165fa",
      "05bc18fa49914567aa4e8eb986ecef8e",
      "2da610ec1f814bcc94fc96eb069e95c4",
      "e3541e42ef774601a49708d99779ca1c",
      "883059c83c7c46feab187d1e3de3d972",
      "0997be3d95e24f3eba10c018c8fcf113",
      "2dc50ac5bbfa43aa8934d13d03eaa5f3",
      "88e2fa4ff8df4d04a7cef50864fa8173",
      "7431b379fee84e839ff5bad6e3fddd7f",
      "6c4694b09ac844c2b2e81d5d10f01f1b",
      "cfe8cce66f414ff69b3fcbf894b4fa36",
      "bb7a149b29ba4d59a80c1611dfcb63c5",
      "84b914fa89f14ce7ada127afa91e1ee1",
      "284d7d0fbabf4c7aa99a265098afdea5",
      "33a3e5a19beb4a68be062dd02863ee71",
      "1fb1dabcb33149ecbb88cb198b7689b0",
      "831bf6fdbee04f2daa0ce537b4675654",
      "7bb6a78503244e47b639f7324efa7976",
      "e55c49f211aa4b758de8f279c8c613eb",
      "e3e45d8e667744949dd24d4b2c084919",
      "c8ab6b1839df47b78925bb182c88bb26",
      "b7f7106cce61491b893577681c39cc8d",
      "143a4291204e435385affa4c68b6682c",
      "d15278eeb3c544768e47c58dd02b16d0",
      "7f47c9b72025440dafed787ddd3e1a5a",
      "467cbd7d7a7e45179d4dcc503460c753",
      "8d3af33f486840baa74ee5da4f8baeb0",
      "8a206ab6b45544e2bdbd107c9a10e260",
      "8fc59b75e95b4fb4aeb98b6b330f868b",
      "14c1cd023c794b11919ad1f40b8d1064",
      "6046f3188a9b401bac48e745c5d78eda",
      "4e7c5d532fb248f191c5e4b28927198d",
      "f22f81ce421c43608cc528718bf105f9",
      "3c7e5e80454543f799afb1c1aa21357f",
      "2030e2d0d56a4c3680ab34512ab66bff",
      "f84c08cc5fff45cc87c61ecd543b9f95",
      "c166394ea89e4d31abbb5c02024c7923",
      "d0d75ef88ea94747bdcde942004b9a09",
      "642bd060d606424d817b79a7d04a6b26",
      "46bffa1c06234873a2b44b5b5d51fe32",
      "1490f8107440493ebc06b6d7a31a319e",
      "d50c7c79fbad4f819db88a0d1deefd06",
      "ba748fd062a744769d82356566c25ac3",
      "c60504221c60414387a60f993d192198",
      "75626e9bbb4248c1b3b9de685dfa6c04",
      "22f154ae23c841a8997867d60d226910",
      "d24110bf49d647229ecdff31df328c28",
      "824713bf79af4b2fb3b7d2ecbc97a953",
      "a4c95f65646246658223706f15d4fe49",
      "a9946a322d824d6985a8044117e96ccf",
      "eb58142c2d124b3b85aad6c5ff08e8fe",
      "92baf69eec97498f8a16b97f9792a7ab",
      "34d1bfff1f82414d8e8638f56ed72121",
      "06c5898be43941c29c181e56e700b8c6",
      "76e870b336d64695bdd5bfcf7b222a29",
      "3662d184ab9c427bac5497f3db89c401",
      "6b9fab1e4c144ede89569ab388cb3bc0",
      "d75c5cffddb14aa0a920513f83658da2",
      "d60ed3f735c947afbca227d6fcd2fc9a",
      "9081ad0004df49c382c5dff53deee9b4",
      "593db8a687994f8290bb2e0226d2716c",
      "7c5f0ece0dd94879a376ecbbf0d9d3b5",
      "d8a997c7fa23424db99a3dc3ee6be855",
      "38cef165275140edae20bf22ae01b3ed",
      "b0116b1eeaa54d98a99aff0524f694c1",
      "0509b6d024ee42939db4626ebcfe86f5",
      "ade902298beb44deb8d104e19214bb76",
      "417fad4df95045f5acc4ef9813037163"
     ]
    },
    "id": "KG-U0djC95tU",
    "outputId": "7a29715c-271d-4c2c-9091-f03864e91212"
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the model: distilbert-base-uncased\n",
      "Enter task type (causal_lm, sequence_classification, token_classification): sequence_classification\n",
      "Enter dataset name or path: imdb\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m9707bc2a-9fc5-48e0-b9eb-7ecb8336c20c\u001b[0m                                                                       \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────── Crew Execution Started ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">9707bc2a-9fc5-48e0-b9eb-7ecb8336c20c</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m 🤖 Agent Started \u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mHuggingFace Fine-Tuning Expert\u001b[0m                                                                          \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mTask: \u001b[0m                                                                                                         \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        Prompt the user to choose the HuggingFace task type they want to perform (options: \"causal_lm\", \u001b[0m       \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m\"sequence_classification\", or \"token_classification\").  \u001b[0m                                                       \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        Once the task type is selected, automatically collect and validate all required parameters:  \u001b[0m          \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        a. model_name (string, valid HuggingFace model ID or local path)  \u001b[0m                                     \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        b. dataset_name_or_path (string, valid HuggingFace dataset name or local file path)  \u001b[0m                  \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        c. task_type (string, must be one of the supported task types)  \u001b[0m                                       \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        d. optional training arguments (learning_rate, num_epochs, train_batch_size, eval_batch_size, \u001b[0m         \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mmax_length, evaluation_strategy, weight_decay, logging_steps).  \u001b[0m                                               \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        Fine-tune the HuggingFace model distilbert-base-uncased for the task sequence_classification using \u001b[0m    \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mthe dataset imdb. \u001b[0m                                                                                             \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        Use the FineTuneTool to configure and run training. Pass model_name='distilbert-base-uncased, \u001b[0m         \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mdataset_name_or_path=imdb, task_type=sequence_classification, and any additional training arguments.\u001b[0m           \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        After collecting and validating inputs:  \u001b[0m                                                              \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        1. Dynamically load the correct model class based on task_type:  \u001b[0m                                      \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m            a. causal_lm -> AutoModelForCausalLM  \u001b[0m                                                             \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m            b. sequence_classification -> AutoModelForSequenceClassification  \u001b[0m                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m            c. token_classification -> AutoModelForTokenClassification  \u001b[0m                                       \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        2. Load and tokenize the dataset according to task_type, applying appropriate truncation, padding, \u001b[0m    \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92mand max_length rules.  \u001b[0m                                                                                        \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        3. Automatically configure TrainingArguments with sensible defaults, allowing overrides from \u001b[0m          \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92muser-supplied training arguments.  \u001b[0m                                                                            \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        4. Run fine-tuning using the FTTool, passing model_name, dataset_name_or_path, task_type, and all \u001b[0m     \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92madditional arguments to `_run()`.  \u001b[0m                                                                            \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        5. On completion, return **only** the JSON string returned by FTTool containing:  \u001b[0m                     \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m            a. \"status\" (success or error)  \u001b[0m                                                                   \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m            b. \"output_dir\" (model save path)  \u001b[0m                                                                \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m            c. \"message\" (summary of fine-tuning)  \u001b[0m                                                            \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[92m        Do not include any additional text, explanations, or formatting outside the returned JSON.\u001b[0m             \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── 🤖 Agent Started ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">HuggingFace Fine-Tuning Expert</span>                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span>                                                                                                         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Prompt the user to choose the HuggingFace task type they want to perform (options: \"causal_lm\", </span>       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">\"sequence_classification\", or \"token_classification\").  </span>                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Once the task type is selected, automatically collect and validate all required parameters:  </span>          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        a. model_name (string, valid HuggingFace model ID or local path)  </span>                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        b. dataset_name_or_path (string, valid HuggingFace dataset name or local file path)  </span>                  <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        c. task_type (string, must be one of the supported task types)  </span>                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        d. optional training arguments (learning_rate, num_epochs, train_batch_size, eval_batch_size, </span>         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">max_length, evaluation_strategy, weight_decay, logging_steps).  </span>                                               <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Fine-tune the HuggingFace model distilbert-base-uncased for the task sequence_classification using </span>    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">the dataset imdb. </span>                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Use the FineTuneTool to configure and run training. Pass model_name='distilbert-base-uncased, </span>         <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">dataset_name_or_path=imdb, task_type=sequence_classification, and any additional training arguments.</span>           <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        After collecting and validating inputs:  </span>                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        1. Dynamically load the correct model class based on task_type:  </span>                                      <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            a. causal_lm -&gt; AutoModelForCausalLM  </span>                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            b. sequence_classification -&gt; AutoModelForSequenceClassification  </span>                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            c. token_classification -&gt; AutoModelForTokenClassification  </span>                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        2. Load and tokenize the dataset according to task_type, applying appropriate truncation, padding, </span>    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and max_length rules.  </span>                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        3. Automatically configure TrainingArguments with sensible defaults, allowing overrides from </span>          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">user-supplied training arguments.  </span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        4. Run fine-tuning using the FTTool, passing model_name, dataset_name_or_path, task_type, and all </span>     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">additional arguments to `_run()`.  </span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        5. On completion, return **only** the JSON string returned by FTTool containing:  </span>                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            a. \"status\" (success or error)  </span>                                                                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            b. \"output_dir\" (model save path)  </span>                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">            c. \"message\" (summary of fine-tuning)  </span>                                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">        Do not include any additional text, explanations, or formatting outside the returned JSON.</span>             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc931a9942274ad89c98850013a8ee54"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
       "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
       "To authenticate with the Hugging Face Hub, create a token in your settings tab \n",
       "(https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
       "You will be able to reuse this secret in all of your notebooks.\n",
       "Please note that authentication is recommended but still optional to access public models or datasets.\n",
       "  warnings.warn(\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
       "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
       "To authenticate with the Hugging Face Hub, create a token in your settings tab \n",
       "(https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
       "You will be able to reuse this secret in all of your notebooks.\n",
       "Please note that authentication is recommended but still optional to access public models or datasets.\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c9da58ef6624dafb4aaa2fbcff513c6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e69ed6351874b7ebf1f87a8e2ef4d84"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "023ccf4ef88945e4bc5dbde33311af0f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3a7bf5ddc7e471ca4f1930bb4b8bf9e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fa01ec95da943a1a5aa6e95636c44c0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a650c82e9ed4aee991adcd3d69f67e6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b920a972007346bebf7b46926e09c9ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70663b54c893426bacb56a658a8d1380"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3adf93757a0d46b0b9a496044f34a0ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb481acaf2234c9287eb42f293e165fa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb7a149b29ba4d59a80c1611dfcb63c5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "143a4291204e435385affa4c68b6682c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c7e5e80454543f799afb1c1aa21357f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75626e9bbb4248c1b3b9de685dfa6c04"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3662d184ab9c427bac5497f3db89c401"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "/tmp/ipython-input-3506620248.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 \n",
       "for `Trainer.__init__`. Use `processing_class` instead.\n",
       "  trainer = Trainer(\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/tmp/ipython-input-3506620248.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 \n",
       "for `Trainer.__init__`. Use `processing_class` instead.\n",
       "  trainer = Trainer(\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18750/18750 42:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.452197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.523511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.575472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m───────────────────────────────────────────\u001b[0m\u001b[35m 🔧 Agent Tool Execution \u001b[0m\u001b[35m───────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mHuggingFace Fine-Tuning Expert\u001b[0m                                                                          \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mThought: \u001b[0m\u001b[92mAction: FTTool\u001b[0m                                                                                        \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m  \u001b[37mUsing Tool: \u001b[0m\u001b[1;92mFTTool\u001b[0m                                                                                             \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭──────────────────────────────────────────── 🔧 Agent Tool Execution ────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">HuggingFace Fine-Tuning Expert</span>                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Thought: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Action: FTTool</span>                                                                                        <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Using Tool: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">FTTool</span>                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m─────────────────────────────────────────────────\u001b[0m\u001b[34m Tool Input \u001b[0m\u001b[34m──────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[38;2;230;219;116;49m\"{\\\"model_name\\\": \\\"distilbert-base-uncased\\\", \\\"dataset_name_or_path\\\": \\\"imdb\\\", \\\"task_type\\\": \u001b[0m             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[38;2;230;219;116;49m\\\"sequence_classification\\\"}\"\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭────────────────────────────────────────────────── Tool Input ───────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #ffffff\">\"{\\\"model_name\\\": \\\"distilbert-base-uncased\\\", \\\"dataset_name_or_path\\\": \\\"imdb\\\", \\\"task_type\\\": </span>             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #ffffff\">\\\"sequence_classification\\\"}\"</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m─────────────────────────────────────────────────\u001b[0m\u001b[32m Tool Output \u001b[0m\u001b[32m─────────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m{\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"status\": \"success\",\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"output_dir\": \"./output/fine_tuning_results\",\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at \u001b[0m                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m./output/fine_tuning_results\"\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m}\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭────────────────────────────────────────────────── Tool Output ──────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">{</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"status\": \"success\",</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"output_dir\": \"./output/fine_tuning_results\",</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at </span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">./output/fine_tuning_results\"</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">}</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ade902298beb44deb8d104e19214bb76"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m ✅ Agent Final Answer \u001b[0m\u001b[32m────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mHuggingFace Fine-Tuning Expert\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThought: I have successfully used the FTTool to fine-tune the model as requested in the prompt. The \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`Observation` contains the required JSON object with \"status\", \"output_dir\", and \"message\". The prompt asks \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mfor a final answer with \"model_save_path\", \"training_details\", and \"status\". I need to re-format the observed\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92moutput to match the expected final answer format. The `output_dir` from the observation maps to \u001b[0m               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`model_save_path`. `training_details` is not explicitly provided in the observation, but the prompt's \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`Observation` example for FTTool suggests `output_dir`, `status`, and `message`. The final answer format \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mspecified at the very end of the prompt is: `model_save_path`, `training_details`, and `status`. I will map \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`output_dir` to `model_save_path` and `status` to `status`. For `training_details`, since no specific metrics\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mwere returned by FTTool in the `Observation`, and the prompt mentions `message` in the FTTool output as a \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m\"summary of fine-tuning\", I will include the `message` under `training_details` as an empty object for now, \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mor just the message. Given the instruction \"Return only the exact JSON object provided by FTTool — no extra \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcommentary, formatting, or explanation.\" and \"A single JSON object returned by the FineTuneTool containing \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mexactly these keys: model_save_path(string) – the path where the fine-tuned model is stored, \u001b[0m                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mtraining_details(object) – metrics and configuration used during training,and status (string) – the final \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mtraining status (e.g., 'success', 'failed').\", it seems I need to construct the *final answer* JSON from the \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`Observation`. The `Observation` itself *is* the FTTool's direct output. I should stick to the format of the \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`Observation` which *is* the FTTool's output. The prompt states \"Return only the exact JSON object provided \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mby FTTool — no extra commentary, formatting, or explanation.\" and then later specifies \"A single JSON object \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mreturned by the FineTuneTool containing exactly these keys: model_save_path(string) – the path where the \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mfine-tuned model is stored, training_details(object) – metrics and configuration used during training,and \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mstatus (string) – the final training status (e.g., 'success', 'failed').\". This is a bit contradictory.\u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mHowever, the instruction \"Return only the exact JSON object provided by FTTool — no extra commentary, \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mformatting, or explanation.\" takes precedence for the direct tool output. But then the \"expected criteria for\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92myour final answer\" section specifies a different set of keys. This implies I should *transform* the tool's \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92moutput into the final answer format.\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mLet's reconcile: The prompt wants *me* to return the *final answer* in a specific format, and *that final \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92manswer* is derived from the FTTool's output.\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThe FTTool's output is:\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m```json\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m{\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"status\": \"success\",\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"output_dir\": \"./output/fine_tuning_results\",\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at \u001b[0m                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m./output/fine_tuning_results\"\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m}\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mThe desired final answer format is:\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m```json\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m{\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"model_save_path\": \"(string)\",\u001b[0m                                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"training_details\": \"(object)\",\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"status\": \"(string)\"\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m}\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mI can map `output_dir` to `model_save_path`.\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mI can map `status` to `status`.\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mFor `training_details`, I can put the `message` from the FTTool output, or an empty object as no explicit \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mmetrics were provided. Since the prompt says `training_details(object) – metrics and configuration used \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mduring training`, and I don't have explicit metrics, putting the `message` that provides a summary of the \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mtraining completion would be the most sensible interpretation. Or, since `training_details` is an object, I \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mcould put `{ \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at \u001b[0m              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m./output/fine_tuning_results\" }`.\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mGiven the emphasis on \"exactly these keys\", I will construct the object to perfectly match them, using the \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mavailable information from the `Observation`.\u001b[0m                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`model_save_path`: from `output_dir`\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`status`: from `status`\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`training_details`: Since no specific metrics are provided, and the `message` provides a summary of the \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92mfine-tuning, I will use the `message` inside the `training_details` object. The prompt specified \u001b[0m              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m`training_details(object)`, so putting `{ \"message\": \"<the message>\" }` is appropriate.```json\u001b[0m                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m{\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"model_save_path\": \"./output/fine_tuning_results\",\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"training_details\": {\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m    \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at \u001b[0m                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m./output/fine_tuning_results\"\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  },\u001b[0m                                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m  \"status\": \"success\"\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m}\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭───────────────────────────────────────────── ✅ Agent Final Answer ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">HuggingFace Fine-Tuning Expert</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Thought: I have successfully used the FTTool to fine-tune the model as requested in the prompt. The </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`Observation` contains the required JSON object with \"status\", \"output_dir\", and \"message\". The prompt asks </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">for a final answer with \"model_save_path\", \"training_details\", and \"status\". I need to re-format the observed</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">output to match the expected final answer format. The `output_dir` from the observation maps to </span>               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`model_save_path`. `training_details` is not explicitly provided in the observation, but the prompt's </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`Observation` example for FTTool suggests `output_dir`, `status`, and `message`. The final answer format </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">specified at the very end of the prompt is: `model_save_path`, `training_details`, and `status`. I will map </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`output_dir` to `model_save_path` and `status` to `status`. For `training_details`, since no specific metrics</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">were returned by FTTool in the `Observation`, and the prompt mentions `message` in the FTTool output as a </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">\"summary of fine-tuning\", I will include the `message` under `training_details` as an empty object for now, </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">or just the message. Given the instruction \"Return only the exact JSON object provided by FTTool — no extra </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">commentary, formatting, or explanation.\" and \"A single JSON object returned by the FineTuneTool containing </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">exactly these keys: model_save_path(string) – the path where the fine-tuned model is stored, </span>                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_details(object) – metrics and configuration used during training,and status (string) – the final </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training status (e.g., 'success', 'failed').\", it seems I need to construct the *final answer* JSON from the </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`Observation`. The `Observation` itself *is* the FTTool's direct output. I should stick to the format of the </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`Observation` which *is* the FTTool's output. The prompt states \"Return only the exact JSON object provided </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">by FTTool — no extra commentary, formatting, or explanation.\" and then later specifies \"A single JSON object </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">returned by the FineTuneTool containing exactly these keys: model_save_path(string) – the path where the </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fine-tuned model is stored, training_details(object) – metrics and configuration used during training,and </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">status (string) – the final training status (e.g., 'success', 'failed').\". This is a bit contradictory.</span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">However, the instruction \"Return only the exact JSON object provided by FTTool — no extra commentary, </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">formatting, or explanation.\" takes precedence for the direct tool output. But then the \"expected criteria for</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">your final answer\" section specifies a different set of keys. This implies I should *transform* the tool's </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">output into the final answer format.</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Let's reconcile: The prompt wants *me* to return the *final answer* in a specific format, and *that final </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">answer* is derived from the FTTool's output.</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The FTTool's output is:</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```json</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">{</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"status\": \"success\",</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"output_dir\": \"./output/fine_tuning_results\",</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at </span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">./output/fine_tuning_results\"</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">}</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">The desired final answer format is:</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```json</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">{</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"model_save_path\": \"(string)\",</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"training_details\": \"(object)\",</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"status\": \"(string)\"</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">}</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">I can map `output_dir` to `model_save_path`.</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">I can map `status` to `status`.</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">For `training_details`, I can put the `message` from the FTTool output, or an empty object as no explicit </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">metrics were provided. Since the prompt says `training_details(object) – metrics and configuration used </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">during training`, and I don't have explicit metrics, putting the `message` that provides a summary of the </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training completion would be the most sensible interpretation. Or, since `training_details` is an object, I </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">could put `{ \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at </span>              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">./output/fine_tuning_results\" }`.</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Given the emphasis on \"exactly these keys\", I will construct the object to perfectly match them, using the </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">available information from the `Observation`.</span>                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`model_save_path`: from `output_dir`</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`status`: from `status`</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`training_details`: Since no specific metrics are provided, and the `message` provides a summary of the </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fine-tuning, I will use the `message` inside the `training_details` object. The prompt specified </span>              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`training_details(object)`, so putting `{ \"message\": \"&lt;the message&gt;\" }` is appropriate.```json</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">{</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"model_save_path\": \"./output/fine_tuning_results\",</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"training_details\": {</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at </span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">./output/fine_tuning_results\"</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  },</span>                                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">  \"status\": \"success\"</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">}</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32m6ff846d3-3995-4828-a1ed-a339937cf5bd\u001b[0m                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mHuggingFace Fine-Tuning Expert\u001b[0m                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Task Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">6ff846d3-3995-4828-a1ed-a339937cf5bd</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">HuggingFace Fine-Tuning Expert</span>                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[32m╭─\u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m Crew Completion \u001b[0m\u001b[32m───────────────────────────────────────────────\u001b[0m\u001b[32m─╮\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[1;32mCrew Execution Completed\u001b[0m                                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mcrew\u001b[0m                                                                                                     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[32m9707bc2a-9fc5-48e0-b9eb-7ecb8336c20c\u001b[0m                                                                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFinal Output: \u001b[0m                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mThought: I have successfully used the FTTool to fine-tune the model as requested in the prompt. The \u001b[0m           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`Observation` contains the required JSON object with \"status\", \"output_dir\", and \"message\". The prompt asks \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mfor a final answer with \"model_save_path\", \"training_details\", and \"status\". I need to re-format the observed\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37moutput to match the expected final answer format. The `output_dir` from the observation maps to \u001b[0m               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`model_save_path`. `training_details` is not explicitly provided in the observation, but the prompt's \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`Observation` example for FTTool suggests `output_dir`, `status`, and `message`. The final answer format \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mspecified at the very end of the prompt is: `model_save_path`, `training_details`, and `status`. I will map \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`output_dir` to `model_save_path` and `status` to `status`. For `training_details`, since no specific metrics\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mwere returned by FTTool in the `Observation`, and the prompt mentions `message` in the FTTool output as a \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m\"summary of fine-tuning\", I will include the `message` under `training_details` as an empty object for now, \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mor just the message. Given the instruction \"Return only the exact JSON object provided by FTTool — no extra \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mcommentary, formatting, or explanation.\" and \"A single JSON object returned by the FineTuneTool containing \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mexactly these keys: model_save_path(string) – the path where the fine-tuned model is stored, \u001b[0m                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mtraining_details(object) – metrics and configuration used during training,and status (string) – the final \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mtraining status (e.g., 'success', 'failed').\", it seems I need to construct the *final answer* JSON from the \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`Observation`. The `Observation` itself *is* the FTTool's direct output. I should stick to the format of the \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`Observation` which *is* the FTTool's output. The prompt states \"Return only the exact JSON object provided \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mby FTTool — no extra commentary, formatting, or explanation.\" and then later specifies \"A single JSON object \u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mreturned by the FineTuneTool containing exactly these keys: model_save_path(string) – the path where the \u001b[0m      \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mfine-tuned model is stored, training_details(object) – metrics and configuration used during training,and \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mstatus (string) – the final training status (e.g., 'success', 'failed').\". This is a bit contradictory.\u001b[0m        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mHowever, the instruction \"Return only the exact JSON object provided by FTTool — no extra commentary, \u001b[0m         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mformatting, or explanation.\" takes precedence for the direct tool output. But then the \"expected criteria for\u001b[0m  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37myour final answer\" section specifies a different set of keys. This implies I should *transform* the tool's \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37moutput into the final answer format.\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mLet's reconcile: The prompt wants *me* to return the *final answer* in a specific format, and *that final \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37manswer* is derived from the FTTool's output.\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mThe FTTool's output is:\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m```json\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m{\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"status\": \"success\",\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"output_dir\": \"./output/fine_tuning_results\",\u001b[0m                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at \u001b[0m                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m./output/fine_tuning_results\"\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m}\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mThe desired final answer format is:\u001b[0m                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m```json\u001b[0m                                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m{\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"model_save_path\": \"(string)\",\u001b[0m                                                                               \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"training_details\": \"(object)\",\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"status\": \"(string)\"\u001b[0m                                                                                         \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m}\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mI can map `output_dir` to `model_save_path`.\u001b[0m                                                                   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mI can map `status` to `status`.\u001b[0m                                                                                \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mFor `training_details`, I can put the `message` from the FTTool output, or an empty object as no explicit \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mmetrics were provided. Since the prompt says `training_details(object) – metrics and configuration used \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mduring training`, and I don't have explicit metrics, putting the `message` that provides a summary of the \u001b[0m     \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mtraining completion would be the most sensible interpretation. Or, since `training_details` is an object, I \u001b[0m   \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mcould put `{ \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at \u001b[0m              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m./output/fine_tuning_results\" }`.\u001b[0m                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mGiven the emphasis on \"exactly these keys\", I will construct the object to perfectly match them, using the \u001b[0m    \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mavailable information from the `Observation`.\u001b[0m                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`model_save_path`: from `output_dir`\u001b[0m                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`status`: from `status`\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`training_details`: Since no specific metrics are provided, and the `message` provides a summary of the \u001b[0m       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37mfine-tuning, I will use the `message` inside the `training_details` object. The prompt specified \u001b[0m              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m`training_details(object)`, so putting `{ \"message\": \"<the message>\" }` is appropriate.```json\u001b[0m                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m{\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"model_save_path\": \"./output/fine_tuning_results\",\u001b[0m                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"training_details\": {\u001b[0m                                                                                        \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m    \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at \u001b[0m                       \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m./output/fine_tuning_results\"\u001b[0m                                                                                  \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  },\u001b[0m                                                                                                           \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m  \"status\": \"success\"\u001b[0m                                                                                          \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m}\u001b[0m                                                                                                              \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m│\u001b[0m                                                                                                                 \u001b[32m│\u001b[0m\n",
       "\u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭──────────────────────────────────────────────── Crew Completion ────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Crew Execution Completed</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">crew</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008000; text-decoration-color: #008000\">9707bc2a-9fc5-48e0-b9eb-7ecb8336c20c</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Output: </span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Thought: I have successfully used the FTTool to fine-tune the model as requested in the prompt. The </span>           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`Observation` contains the required JSON object with \"status\", \"output_dir\", and \"message\". The prompt asks </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">for a final answer with \"model_save_path\", \"training_details\", and \"status\". I need to re-format the observed</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output to match the expected final answer format. The `output_dir` from the observation maps to </span>               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`model_save_path`. `training_details` is not explicitly provided in the observation, but the prompt's </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`Observation` example for FTTool suggests `output_dir`, `status`, and `message`. The final answer format </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">specified at the very end of the prompt is: `model_save_path`, `training_details`, and `status`. I will map </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`output_dir` to `model_save_path` and `status` to `status`. For `training_details`, since no specific metrics</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">were returned by FTTool in the `Observation`, and the prompt mentions `message` in the FTTool output as a </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">\"summary of fine-tuning\", I will include the `message` under `training_details` as an empty object for now, </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">or just the message. Given the instruction \"Return only the exact JSON object provided by FTTool — no extra </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">commentary, formatting, or explanation.\" and \"A single JSON object returned by the FineTuneTool containing </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">exactly these keys: model_save_path(string) – the path where the fine-tuned model is stored, </span>                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">training_details(object) – metrics and configuration used during training,and status (string) – the final </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">training status (e.g., 'success', 'failed').\", it seems I need to construct the *final answer* JSON from the </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`Observation`. The `Observation` itself *is* the FTTool's direct output. I should stick to the format of the </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`Observation` which *is* the FTTool's output. The prompt states \"Return only the exact JSON object provided </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">by FTTool — no extra commentary, formatting, or explanation.\" and then later specifies \"A single JSON object </span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">returned by the FineTuneTool containing exactly these keys: model_save_path(string) – the path where the </span>      <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">fine-tuned model is stored, training_details(object) – metrics and configuration used during training,and </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">status (string) – the final training status (e.g., 'success', 'failed').\". This is a bit contradictory.</span>        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">However, the instruction \"Return only the exact JSON object provided by FTTool — no extra commentary, </span>         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">formatting, or explanation.\" takes precedence for the direct tool output. But then the \"expected criteria for</span>  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">your final answer\" section specifies a different set of keys. This implies I should *transform* the tool's </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output into the final answer format.</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Let's reconcile: The prompt wants *me* to return the *final answer* in a specific format, and *that final </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">answer* is derived from the FTTool's output.</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">The FTTool's output is:</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```json</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">{</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"status\": \"success\",</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"output_dir\": \"./output/fine_tuning_results\",</span>                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at </span>                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">./output/fine_tuning_results\"</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">}</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">The desired final answer format is:</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```json</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">{</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"model_save_path\": \"(string)\",</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"training_details\": \"(object)\",</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"status\": \"(string)\"</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">}</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">I can map `output_dir` to `model_save_path`.</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">I can map `status` to `status`.</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">For `training_details`, I can put the `message` from the FTTool output, or an empty object as no explicit </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">metrics were provided. Since the prompt says `training_details(object) – metrics and configuration used </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">during training`, and I don't have explicit metrics, putting the `message` that provides a summary of the </span>     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">training completion would be the most sensible interpretation. Or, since `training_details` is an object, I </span>   <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">could put `{ \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at </span>              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">./output/fine_tuning_results\" }`.</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Given the emphasis on \"exactly these keys\", I will construct the object to perfectly match them, using the </span>    <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">available information from the `Observation`.</span>                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`model_save_path`: from `output_dir`</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`status`: from `status`</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`training_details`: Since no specific metrics are provided, and the `message` provides a summary of the </span>       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">fine-tuning, I will use the `message` inside the `training_details` object. The prompt specified </span>              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`training_details(object)`, so putting `{ \"message\": \"&lt;the message&gt;\" }` is appropriate.```json</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">{</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"model_save_path\": \"./output/fine_tuning_results\",</span>                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"training_details\": {</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    \"message\": \"Fine-tuned distilbert-base-uncased for sequence_classification saved at </span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">./output/fine_tuning_results\"</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  },</span>                                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  \"status\": \"success\"</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">}</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">│</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = \"./output/fine_tuning_results\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ],
   "metadata": {
    "id": "gao6VHTc18jG"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "classifier = pipeline(\"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "text1 = \"Thug life is one of the worst movie of all time\"\n",
    "text2 = \"It's the best movie i have ever seen in my life\"\n",
    "result1 = classifier(text1)\n",
    "result2 = classifier(text2)\n",
    "print(result1)\n",
    "print(result2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfDVWHII95p8",
    "outputId": "f8337721-9085-4d75-d6fe-e7963b9df788"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9996126294136047}]\n",
      "[{'label': 'LABEL_1', 'score': 0.9997625946998596}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "1np2wD3a95kV"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
